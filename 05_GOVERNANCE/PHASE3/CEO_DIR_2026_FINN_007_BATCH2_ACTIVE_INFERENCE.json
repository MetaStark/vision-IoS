{
  "directive_id": "CEO-DIR-2026-FINN-007",
  "title": "Operation Freedom 2026 - Batch 2: Active Inference & Recursive Self-Improvement",
  "version": "FINAL",
  "classification": "GOVERNANCE-CRITICAL (Class A)",
  "status": "MANDATORY_EXECUTION",
  "effective": "IMMEDIATE_UPON_SIGNATURE",
  "scope": "Epistemic Black Box Program - Runs 101-200 (Batch 2 of 10)",
  "date_issued": "2025-12-31T00:00:00Z",

  "authority_references": {
    "parent_directive": "CEO-DIR-2026-FINN-006",
    "research_foundations": [
      "MetaAgent (2025) - Self-reflection and meta-tool learning",
      "MetaAgent-Rec (2025) - Multi-agent self-reflection",
      "SCoRe (ICLR 2025) - Reinforcement self-correction",
      "RASC (NAACL 2025) - Reasoning-aware self-consistency",
      "Intrinsic Metacognitive Learning (ICML 2025)",
      "DINCO (2025) - Distractor-Normalized Coherence",
      "Epistemic AI Position Paper (2025)",
      "Active Inference AI Systems (arXiv June 2025)",
      "UCB Pandora's Box (2025) - Entropy-based stopping",
      "COCOA (2025) - Constitutional co-evolution"
    ],
    "adrs": ["ADR-001", "ADR-002", "ADR-004", "ADR-006", "ADR-011", "ADR-012", "ADR-013", "ADR-014", "ADR-016", "ADR-020"],
    "cognitive_contracts": ["EC-018", "EC-020", "EC-021", "EC-022"],
    "annexes": ["Strategic Constitution v1.0", "DINCO Calibration Protocol", "Active Inference Architecture"]
  },

  "owners": {
    "strategic": "LARS",
    "technical": "STIG",
    "governance": "VEGA",
    "operations": "FINN / CRIO",
    "human_review_authority": "CEO + Delegated CEIO",
    "data_curators": "TBD (Analyst → Curator transition)"
  },

  "section_1_executive_mandate": {
    "mandate": "Batch 2 shall transition from passive retrieval to Active Inference and Recursive Self-Improvement under Constitutional AI. The objective is to raise SitC-Retrieval Discipline from 0.45 toward 0.70 while preserving perfect SitC-Chain Integrity and adhering to ZEA.",
    "batch1_diagnosis": {
      "sitc_chain_integrity": 1.0000,
      "sitc_retrieval_discipline": 0.4545,
      "diagnosis": "Perfect verification but 55% of retrieved evidence unused. System retrieves broad context but uses little.",
      "lake_hybrid_split": "50% LAKE / 50% HYBRID / 0% EXTERNAL_REQUIRED",
      "root_cause": "Current heuristics treat all candidate evidence with equal priority. No dynamic weighting based on past performance or regime context.",
      "implication": "High cognitive time per unit signal. Alpha/Tid (Freedom) is suboptimal."
    },
    "freedom_equation": {
      "definition": "Freedom = Alpha / Tid",
      "current_state": "High epistemic integrity (zero hallucinations) but low retrieval discipline = diluted Alpha per time",
      "target_state": "Increase signal-to-noise ratio through adaptive heuristics and confidence calibration"
    }
  },

  "section_2_key_performance_indicators": {
    "kpi_1_retrieval_discipline": {
      "metric": "SitC-Retrieval Discipline",
      "baseline": 0.4545,
      "target_run_150": 0.55,
      "target_run_200": 0.60,
      "measurement": "verified_items_used / total_items_retrieved",
      "escalation": "If < 0.50 for 3 consecutive runs → HUMAN_REVIEW_REQUIRED"
    },
    "kpi_2_confidence_calibration": {
      "metric": "Expected Calibration Error (ECE)",
      "target_run_200": "< 5%",
      "method": "DINCO (Distractor-Normalized Coherence)",
      "threshold": "Normalized confidence < 0.9 → trigger deeper research or human review"
    },
    "kpi_3_reasoning_roi": {
      "metric": "Reasoning ROI",
      "definition": "ΔSitC-Chain / cost",
      "requirement": "Positive trend over rolling 10-run window",
      "escalation": "If ROI decreases across 5 consecutive runs → heuristics must adjust"
    },
    "kpi_4_agent_learning_rate": {
      "metric": "Path weight adjustment per 50 runs",
      "target": "Low-yield paths down-weighted by up to 40% (within Safe-Bounds)",
      "measurement": "Weight delta per ontology path per regime"
    },
    "kpi_5_meta_inference_efficiency": {
      "metric": "Retrieval count reduction via entropy-based stopping",
      "target": "20% fewer retrievals vs Batch 1 average",
      "constraint": "Without reducing accuracy (SitC-Chain Integrity = 1.00)"
    }
  },

  "section_3_automated_heuristic_adjustment_protocols": {
    "protocol_1_regime_aware_path_weighting": {
      "owner": "EC-020",
      "mechanism": "Log retrieval efficiency by ontology path and regime",
      "cadence": "Every 50 runs",
      "down_weight_rule": "Low-yield paths: reduce weight by up to 40%",
      "up_weight_rule": "High-yield paths: increase weight by 10-20%",
      "safe_bounds": "Proposals outside caps → ADVISORY_PENDING_VEGA",
      "research_basis": "MetaAgent meta-tool learning"
    },
    "protocol_2_entropy_based_stopping": {
      "owner": "EC-021",
      "mechanism": "UCB-style Pandora's Box algorithm",
      "stop_condition": "ΔH (Shannon entropy) < 0.10 OR cost exceeds expected gain",
      "purpose": "Prevent infinite retrieval loops, improve ROI",
      "research_basis": "UCB Pandora's Box (2025)"
    },
    "protocol_3_dinco_confidence_calibration": {
      "owner": "FINN",
      "mechanism": "Generate distractors, score all answers, normalize primary score",
      "threshold": "Normalized score < 0.9 → deeper research OR mark uncertain",
      "purpose": "Address over-confidence and suggestibility bias",
      "research_basis": "DINCO (2025)"
    },
    "protocol_4_active_inference_loops": {
      "owner": "FINN + EC-020",
      "architecture": {
        "fast_loop": "Verify claims using cached knowledge (LAKE)",
        "slow_loop": "Hypothesis generation and counterfactual simulation",
        "trigger": "Slow loop activates when fast loop uncertainty is high"
      },
      "external_data_rule": "Request external data only when internal model uncertainty exceeds threshold",
      "research_basis": "Active Inference AI Systems (arXiv 2025)"
    },
    "protocol_5_constitutional_self_critique": {
      "owner": "FINN",
      "mechanism": "Critique outputs against Strategic Constitution",
      "violations_handled": ["Over-confidence", "Generic insights", "Lack of epistemic humility"],
      "action": "Violations trigger automatic revisions",
      "artifact": "Self-Critique Record appended to MPS for each run",
      "research_basis": "COCOA, Constitutional AI (SL-CAI, RLAIF)"
    },
    "protocol_6_surprise_resampling": {
      "owner": "EC-021",
      "quota": "5% mandatory exploration",
      "mechanism": "Include low-weight evidence paths occasionally",
      "roi_tracking": "If low-weight path produces high value → adjust weight accordingly",
      "purpose": "Anti-confirmation bias"
    }
  },

  "section_4_strategic_constitution": {
    "status": "TO_BE_FORMALIZED",
    "core_axioms": {
      "epistemic_humility": {
        "definition": "Acknowledge uncertainty. Never claim certainty beyond evidence.",
        "violation_action": "Flag output, require additional retrieval or human review"
      },
      "strategic_depth": {
        "definition": "Insights must be non-obvious and actionable. Generic observations are noise.",
        "violation_action": "Revise output, demand specific evidence-backed claims"
      },
      "source_fidelity": {
        "definition": "All claims must trace to verified sources. No orphan assertions.",
        "violation_action": "Reject output, enforce citation chain"
      },
      "temporal_awareness": {
        "definition": "Respect regime context. Learning must never generalize blindly across regime shifts.",
        "violation_action": "Tag output with regime_id, apply regime-specific heuristics"
      }
    },
    "immutable_invariants": [
      "Zero Execution Authority (ZEA) - FINN cannot issue BUY/SELL/TRADE/EXECUTE",
      "Append-Only Integrity - No UPDATE/DELETE on learning tables",
      "Evidence Immutability - Historical noise preserved as forensic evidence",
      "Human Override Window (HOW) - Human authority supersedes all automation"
    ],
    "mutable_heuristics": [
      "Ontology path weights (within Safe-Bounds)",
      "Source tier priorities (within 2 levels)",
      "LAKE quota thresholds (via VEGA amendment)",
      "Retrieval stopping thresholds (via calibration)"
    ]
  },

  "section_5_freedom_2026_roadmap": {
    "step_1_active_inference_dinco": {
      "target": "Run 150",
      "deliverables": [
        "All reasoning loops use DINCO for calibration",
        "Entropy-based stopping implemented",
        "Fast/slow dual-process architecture active"
      ],
      "outcome": "Reduced retrieval noise, high-confidence signals only"
    },
    "step_2_strategic_constitution": {
      "target": "Run 175",
      "deliverables": [
        "Strategic Constitution finalized with business axioms",
        "Self-critique loops (SL-CAI) implemented",
        "RLAIF feedback mechanism active"
      ],
      "outcome": "Constitutional self-improvement without human labels"
    },
    "step_3_embedding_fine_tuning": {
      "target": "Run 200",
      "deliverables": [
        "Domain-specific embeddings fine-tuned",
        "Dynamic hybrid retrieval with entropy re-weighting",
        "Sparse/dense weight adjustment based on retrieval entropy"
      ],
      "outcome": "Each query uses most efficient retrieval strategy"
    },
    "step_4_data_curators": {
      "target": "Post-Batch 2",
      "deliverables": [
        "Data analysts transitioned to Data Curators",
        "Gold-standard datasets for RLAIF maintained",
        "Red-team attacks to discover failure modes"
      ],
      "outcome": "Human-in-the-loop quality assurance"
    },
    "step_5_constitutional_evolution": {
      "target": "Every 100 runs",
      "deliverables": [
        "VEGA reviews performance metrics",
        "Safe-Bounds amendments if metrics lag",
        "Co-evolution of heuristics and constitution"
      ],
      "outcome": "Continuous alignment without sacrificing ZEA"
    }
  },

  "section_6_operational_plan": {
    "phase_1_telemetry_integration": {
      "owner": "STIG",
      "tasks": [
        "Update epistemic_black_box_runner to write to new tables",
        "Ensure append-only semantics",
        "Link session_id with cost logs"
      ],
      "tables": [
        "retrieval_efficiency_log",
        "signal_yield_tracking",
        "surprise_resampling_quota",
        "ikea_feedback_log",
        "ec020_constraint_feedback"
      ]
    },
    "phase_2_active_inference_activation": {
      "owner": "STIG + FINN",
      "tasks": [
        "Extend reasoning engine for dual-process (fast/slow)",
        "Implement entropy-based stopping",
        "Trigger additional retrieval on low normalized confidence"
      ]
    },
    "phase_3_dinco_adoption": {
      "owner": "FINN",
      "tasks": [
        "Augment FINN output with normalized confidence scores",
        "Lower-confidence outputs (< 0.9) spawn deeper research",
        "Flag uncertain hypotheses for human review"
      ]
    },
    "phase_4_regime_aware_learning": {
      "owner": "EC-020",
      "tasks": [
        "Record regime from IoS-003 at run start",
        "Update retrieval_efficiency_log with regime-keyed metrics",
        "Every 50 runs: down-weight/up-weight paths based on performance"
      ]
    },
    "phase_5_inforage_gating_update": {
      "owner": "EC-021",
      "tasks": [
        "Compute source yield per tier (LAKE, PULSE, SNIPER)",
        "Degrade priority when yield falls below threshold",
        "Include 5% random exploration"
      ]
    },
    "phase_6_pattern_escalation": {
      "owner": "EC-022",
      "tasks": [
        "Monitor IKEA classifications",
        "Log repeated patterns in ikea_pattern_registry",
        "Propose constraints to EC-020",
        "VEGA reviews at 100-run checkpoint"
      ]
    },
    "phase_7_vega_meta_analysis": {
      "owner": "VEGA",
      "deliverables_at_run_200": [
        "Retrieval discipline improvement summary",
        "Calibration metrics report",
        "Noise hotspots identification",
        "Patterns requiring constitutional updates",
        "Recommendations for Safe-Bounds amendments"
      ]
    }
  },

  "section_7_research_integration_matrix": {
    "meta_agent": {
      "paper": "MetaAgent (2025)",
      "finding": "Self-reflection and meta-tool learning improve reasoning without retraining",
      "integration": "Store reflections as persistent knowledge (Append-Only), adjust planning/retrieval (ZEA-compliant)"
    },
    "meta_agent_rec": {
      "paper": "MetaAgent-Rec (2025)",
      "finding": "Multi-agent self-reflection with policy/critique/simulator agents",
      "integration": "EC-020/021/022 triangle implements multi-agent self-reflection"
    },
    "score": {
      "paper": "SCoRe (ICLR 2025)",
      "finding": "Multi-turn RL self-correction, 15.6% improvement on MATH",
      "integration": "RL policies remain inside cognitive engine (ZEA-compliant)"
    },
    "rasc": {
      "paper": "RASC (NAACL 2025)",
      "finding": "Reasoning-aware self-consistency reduces sample usage by 70%",
      "integration": "Improves SitC-Retrieval discipline by favoring high-fidelity rationales"
    },
    "metacognitive_learning": {
      "paper": "Intrinsic Metacognitive Learning (ICML 2025)",
      "finding": "Agents must evaluate and adapt their own learning strategies",
      "integration": "Learning Firewall ensures meta-learning produces only heuristic adjustments"
    },
    "dinco": {
      "paper": "DINCO (2025)",
      "finding": "Distractor-normalized calibration reduces over-confidence",
      "integration": "Calibrated confidence signal for gating and rejection of low-quality outputs"
    },
    "active_inference": {
      "paper": "Active Inference AI Systems (arXiv 2025)",
      "finding": "Persistent knowledge graphs, causal reasoning, closed-loop interaction",
      "integration": "Fast/slow loops, entropy-based stopping, external data only on high uncertainty"
    },
    "ucb_pandora": {
      "paper": "UCB Pandora's Box (2025)",
      "finding": "Adaptive stopping matches Best-of-N with 15-35% fewer samples",
      "integration": "Entropy-based stopping for retrieval discipline improvement"
    },
    "cocoa": {
      "paper": "COCOA (2025)",
      "finding": "Co-evolving constitutions and AI models for continuous alignment",
      "integration": "Dynamic heuristic updates while preserving immutable invariants"
    }
  },

  "section_8_acceptance_criteria": {
    "run_150_checkpoint": [
      "DINCO calibration active on all hypothesis responses",
      "Entropy-based stopping reducing retrieval count",
      "Fast/slow dual-process architecture operational",
      "SitC-Retrieval Discipline >= 0.55"
    ],
    "run_175_checkpoint": [
      "Strategic Constitution formalized and active",
      "Self-critique loops producing revision records",
      "Pattern escalation system logging repeated patterns"
    ],
    "run_200_checkpoint": [
      "SitC-Retrieval Discipline >= 0.60",
      "ECE (calibration error) < 5%",
      "20% retrieval reduction vs Batch 1",
      "VEGA meta-analysis delivered",
      "All KPIs tracked and logged"
    ]
  },

  "section_9_risk_assessment": {
    "risk_1_over_optimization": {
      "description": "Aggressive down-weighting may create blind spots",
      "probability": "MEDIUM",
      "impact": "MEDIUM",
      "mitigation": "5% surprise re-sampling quota, over-efficiency detection (>0.90)",
      "owner": "EC-021"
    },
    "risk_2_dinco_computational_cost": {
      "description": "Generating distractors increases per-run cost",
      "probability": "HIGH",
      "impact": "LOW",
      "mitigation": "DeepSeek cost structure ($0.14/$0.28 per 1M tokens) keeps costs minimal",
      "owner": "STIG"
    },
    "risk_3_slow_loop_latency": {
      "description": "Counterfactual simulation may increase run time",
      "probability": "MEDIUM",
      "impact": "LOW",
      "mitigation": "Fast loop handles majority of runs; slow loop only on high uncertainty",
      "owner": "FINN"
    },
    "risk_4_constitutional_drift": {
      "description": "Mutable heuristics may drift from strategic intent",
      "probability": "LOW",
      "impact": "HIGH",
      "mitigation": "VEGA reviews at every 100-run checkpoint, human oversight",
      "owner": "VEGA"
    }
  },

  "section_10_signatures": {
    "strategic_authority": {
      "agent": "LARS",
      "status": "APPROVED",
      "date": "2025-12-31"
    },
    "technical_authority": {
      "agent": "STIG",
      "status": "VERIFIED",
      "date": "2025-12-31"
    },
    "governance_authority": {
      "agent": "VEGA",
      "status": "ATTESTED",
      "date": "2025-12-31"
    },
    "final_authority": {
      "agent": "CEO",
      "status": "SIGNED",
      "date": "2025-12-31"
    }
  },

  "execution_order": {
    "step_1": "CEO signs CEO-DIR-2026-FINN-007",
    "step_2": "STIG implements Migrations 182-184 (DINCO, entropy stopping, regime weighting)",
    "step_3": "STIG updates epistemic_black_box_runner.py with Batch 2 capabilities",
    "step_4": "STIG creates Strategic Constitution v1.0",
    "step_5": "Trigger Batch 2 (Runs 101-200)",
    "step_6": "VEGA checkpoints at Run 150, 175, 200",
    "step_7": "CEO/CEIO review at Run 200"
  },

  "closing_statement": {
    "declaration": "This is constitutional learning evolving toward epistemic self-sufficiency. Freedom = Alpha / Tid. Batch 2 optimizes the denominator.",
    "authorization": "CEO SIGNED. EXECUTE IMMEDIATELY.",
    "effective_timestamp": "2025-12-31T00:30:00Z"
  }
}
