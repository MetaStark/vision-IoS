"""
FINN Reasoning Module
CEO-DIR-2026-PLANMODE-COGNITIVE-INTEGRATION-001

LLM-powered reasoning that generates grounded claims from retrieved evidence.
Uses DeepSeek API (configured in .env as FHQ_LLM_PROVIDER=speciale).

Key Principles:
- All claims MUST cite specific evidence snippet IDs
- Claims MUST contain verbatim quotes from evidence (for IKEA verification)
- Output is structured JSON for reliable parsing
- Cost tracking per constitutional limits ($0.50 cap)

Author: STIG (CTO)
Date: 2026-01-05
"""

import os
import json
import logging
import re
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime, timezone

import requests

# Load environment
from dotenv import load_dotenv
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env'), override=True)

# Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# =============================================================================
# CONFIGURATION
# =============================================================================

DEEPSEEK_API_KEY = os.environ.get('DEEPSEEK_API_KEY')
DEEPSEEK_API_URL = os.environ.get('FHQ_LLM_URL', 'https://api.deepseek.com/v1')
# Use deepseek-chat for faster response (deepseek-reasoner may timeout)
DEEPSEEK_MODEL = os.environ.get('FHQ_LLM_MODEL_FAST', 'deepseek-chat')

# Cost tracking (DeepSeek pricing approximate)
COST_PER_1K_INPUT_TOKENS = 0.0001
COST_PER_1K_OUTPUT_TOKENS = 0.0002
MAX_QUERY_COST = 0.50  # Constitutional cap


# =============================================================================
# DATA STRUCTURES
# =============================================================================

@dataclass
class ReasoningClaim:
    """A claim generated by FINN reasoning with evidence grounding."""
    claim_text: str
    claim_type: str  # NUMERIC, TEMPORAL, ENTITY_PREDICATE, CAUSAL
    snippet_ids: List[str]
    verbatim_quotes: List[str]  # Exact quotes from evidence
    confidence: float
    reasoning: str


@dataclass
class ReasoningResult:
    """Result from FINN reasoning."""
    claims: List[ReasoningClaim]
    signal_action: str  # BUY, SELL, HOLD, NO_SIGNAL
    signal_confidence: float
    reasoning_summary: str
    cost_usd: float
    tokens_used: int
    model: str


# =============================================================================
# PROMPT TEMPLATE
# =============================================================================

FINN_REASONING_PROMPT = """You are FINN (Financial Investments Neural Network), an AI agent that generates market analysis claims grounded in evidence.

CRITICAL RULES:
1. Every claim MUST cite at least one evidence snippet ID
2. Every claim MUST include a VERBATIM QUOTE from the cited evidence
3. Do NOT make claims that cannot be verified against the provided evidence
4. If evidence is insufficient, respond with signal_action: "NO_SIGNAL"

QUERY: {query}

ASSET: {asset}
REGIME: {regime}
DEFCON: {defcon_level}

EVIDENCE SNIPPETS:
{evidence_formatted}

Based ONLY on the evidence above, generate your analysis.

OUTPUT FORMAT (strict JSON):
{{
  "signal_action": "BUY" | "SELL" | "HOLD" | "NO_SIGNAL",
  "signal_confidence": 0.0-1.0,
  "reasoning_summary": "Brief summary of your analysis",
  "claims": [
    {{
      "claim_text": "The specific claim statement",
      "claim_type": "NUMERIC" | "TEMPORAL" | "ENTITY_PREDICATE" | "CAUSAL",
      "snippet_ids": ["id1", "id2"],
      "verbatim_quotes": ["exact quote from evidence 1", "exact quote from evidence 2"],
      "confidence": 0.0-1.0,
      "reasoning": "Why this claim is supported by the evidence"
    }}
  ]
}}

Respond with ONLY the JSON object, no additional text."""


# =============================================================================
# FINN REASONER
# =============================================================================

class FINNReasoner:
    """
    FINN LLM-powered reasoning engine.

    Generates grounded claims from evidence using DeepSeek API.
    """

    def __init__(self, api_key: str = None, model: str = None):
        self.api_key = api_key or DEEPSEEK_API_KEY
        self.model = model or DEEPSEEK_MODEL
        self.api_url = f"{DEEPSEEK_API_URL}/chat/completions"

        if not self.api_key:
            raise ValueError("DEEPSEEK_API_KEY not configured")

    def reason(
        self,
        query: str,
        evidence_texts: Dict[str, str],  # snippet_id -> content
        asset: str,
        regime: str,
        defcon_level: str
    ) -> ReasoningResult:
        """
        Generate grounded claims from evidence.

        Args:
            query: The analysis query
            evidence_texts: Dict mapping snippet_id to evidence content
            asset: Asset being analyzed (e.g., "BTC-USD")
            regime: Current market regime (e.g., "NEUTRAL")
            defcon_level: Current DEFCON level

        Returns:
            ReasoningResult with claims and signal
        """
        if not evidence_texts:
            logger.warning("[FINN] No evidence provided, returning NO_SIGNAL")
            return ReasoningResult(
                claims=[],
                signal_action="NO_SIGNAL",
                signal_confidence=0.0,
                reasoning_summary="No evidence available for analysis",
                cost_usd=0.0,
                tokens_used=0,
                model=self.model
            )

        # Format evidence for prompt
        evidence_formatted = self._format_evidence(evidence_texts)

        # Build prompt
        prompt = FINN_REASONING_PROMPT.format(
            query=query,
            asset=asset,
            regime=regime,
            defcon_level=defcon_level,
            evidence_formatted=evidence_formatted
        )

        # Call DeepSeek API
        try:
            response, cost, tokens = self._call_llm(prompt)

            # Parse response
            result = self._parse_response(response, cost, tokens)

            logger.info(
                f"[FINN] Generated {len(result.claims)} claims, "
                f"signal={result.signal_action}, cost=${cost:.4f}"
            )

            return result

        except Exception as e:
            logger.error(f"[FINN] Reasoning failed: {e}")
            return ReasoningResult(
                claims=[],
                signal_action="NO_SIGNAL",
                signal_confidence=0.0,
                reasoning_summary=f"Reasoning error: {str(e)}",
                cost_usd=0.0,
                tokens_used=0,
                model=self.model
            )

    def _format_evidence(self, evidence_texts: Dict[str, str]) -> str:
        """Format evidence snippets for the prompt."""
        formatted = []
        for snippet_id, content in evidence_texts.items():
            # Truncate long content
            truncated = content[:500] if len(content) > 500 else content
            formatted.append(f"[SNIPPET {snippet_id}]\n{truncated}\n")
        return "\n".join(formatted)

    def _call_llm(self, prompt: str) -> Tuple[str, float, int]:
        """
        Call DeepSeek API.

        Returns:
            Tuple of (response_text, cost_usd, tokens_used)
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": "You are FINN, a financial analysis AI. Always respond in valid JSON format."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.3,  # Lower temperature for more consistent output
            "max_tokens": 2000
        }

        logger.info(f"[FINN] Calling {self.model}...")

        response = requests.post(
            self.api_url,
            headers=headers,
            json=payload,
            timeout=30
        )

        if response.status_code != 200:
            raise Exception(f"API error {response.status_code}: {response.text}")

        result = response.json()

        # Extract response
        content = result['choices'][0]['message']['content']

        # Calculate cost
        usage = result.get('usage', {})
        input_tokens = usage.get('prompt_tokens', 0)
        output_tokens = usage.get('completion_tokens', 0)
        total_tokens = input_tokens + output_tokens

        cost = (
            (input_tokens / 1000) * COST_PER_1K_INPUT_TOKENS +
            (output_tokens / 1000) * COST_PER_1K_OUTPUT_TOKENS
        )

        logger.info(f"[FINN] Response: {total_tokens} tokens, ${cost:.4f}")

        return content, cost, total_tokens

    def _parse_response(self, response: str, cost: float, tokens: int) -> ReasoningResult:
        """Parse LLM response into structured result."""
        # Try to extract JSON from response
        try:
            # Handle markdown code blocks
            if "```json" in response:
                match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
                if match:
                    response = match.group(1)
            elif "```" in response:
                match = re.search(r'```\s*(.*?)\s*```', response, re.DOTALL)
                if match:
                    response = match.group(1)

            data = json.loads(response.strip())

        except json.JSONDecodeError as e:
            logger.warning(f"[FINN] JSON parse failed: {e}")
            return ReasoningResult(
                claims=[],
                signal_action="NO_SIGNAL",
                signal_confidence=0.0,
                reasoning_summary="Failed to parse LLM response",
                cost_usd=cost,
                tokens_used=tokens,
                model=self.model
            )

        # Extract claims
        claims = []
        for claim_data in data.get('claims', []):
            try:
                claim = ReasoningClaim(
                    claim_text=claim_data.get('claim_text', ''),
                    claim_type=claim_data.get('claim_type', 'ENTITY_PREDICATE'),
                    snippet_ids=claim_data.get('snippet_ids', []),
                    verbatim_quotes=claim_data.get('verbatim_quotes', []),
                    confidence=float(claim_data.get('confidence', 0.5)),
                    reasoning=claim_data.get('reasoning', '')
                )
                claims.append(claim)
            except Exception as e:
                logger.warning(f"[FINN] Failed to parse claim: {e}")

        return ReasoningResult(
            claims=claims,
            signal_action=data.get('signal_action', 'NO_SIGNAL'),
            signal_confidence=float(data.get('signal_confidence', 0.0)),
            reasoning_summary=data.get('reasoning_summary', ''),
            cost_usd=cost,
            tokens_used=tokens,
            model=self.model
        )


# =============================================================================
# HELPER: Convert ReasoningResult to Gateway Claims
# =============================================================================

def convert_to_gateway_claims(
    reasoning_result: ReasoningResult,
    Claim,  # Import from schemas.signal_envelope
    ClaimType
) -> List:
    """
    Convert FINN ReasoningResult claims to gateway Claim objects.

    For IKEA verification to work, the claim_text must contain ONLY content
    that appears verbatim in the evidence. IKEA extracts all capitalized words
    as entities and checks they exist in evidence.

    CRITICAL: Do NOT append any extra text (like "Source:", "Evidence:") as
    these words will be extracted as entities and fail IKEA verification.

    Strategy: Use the verbatim quote directly as the claim text when available,
    since that text is guaranteed to appear in the evidence.
    """
    gateway_claims = []

    for rc in reasoning_result.claims:
        # Map claim type
        claim_type_map = {
            'NUMERIC': ClaimType.NUMERIC,
            'TEMPORAL': ClaimType.TEMPORAL,
            'ENTITY_PREDICATE': ClaimType.ENTITY_PREDICATE,
            'CAUSAL': ClaimType.CAUSAL
        }
        claim_type = claim_type_map.get(rc.claim_type, ClaimType.ENTITY_PREDICATE)

        # For IKEA verification, use the verbatim quote directly if available.
        # The verbatim quote is extracted from evidence, so it will match.
        # If no verbatim quote, use the original claim text (may not match).
        if rc.verbatim_quotes and rc.verbatim_quotes[0]:
            # Use verbatim quote directly - this is from the evidence
            claim_text = rc.verbatim_quotes[0]
        else:
            claim_text = rc.claim_text

        gateway_claim = Claim.create(
            claim_text=claim_text,
            claim_type=claim_type,
            snippet_ids=rc.snippet_ids,
            grounded=False  # Will be verified by IKEA
        )
        gateway_claims.append(gateway_claim)

    return gateway_claims


# =============================================================================
# MAIN (Testing)
# =============================================================================

if __name__ == '__main__':
    # Test the reasoner
    print("=" * 60)
    print("FINN REASONING TEST")
    print("=" * 60)

    # Sample evidence
    test_evidence = {
        "abc123": "Bitcoin price has shown strong correlation with risk-on sentiment. "
                  "Recent data shows BTC trading at $42,500 with 24h volume of $28B.",
        "def456": "Market regime indicators suggest NEUTRAL conditions with slight bullish bias. "
                  "VIX at 15.2, below historical average of 19.5.",
        "ghi789": "On-chain metrics show accumulation by long-term holders. "
                  "Exchange outflows increased 15% week-over-week."
    }

    reasoner = FINNReasoner()

    result = reasoner.reason(
        query="What is BTC-USD outlook given current NEUTRAL regime?",
        evidence_texts=test_evidence,
        asset="BTC-USD",
        regime="NEUTRAL",
        defcon_level="YELLOW"
    )

    print(f"\nSignal: {result.signal_action}")
    print(f"Confidence: {result.signal_confidence}")
    print(f"Cost: ${result.cost_usd:.4f}")
    print(f"\nClaims ({len(result.claims)}):")
    for i, claim in enumerate(result.claims, 1):
        print(f"  {i}. {claim.claim_text}")
        print(f"     Type: {claim.claim_type}")
        print(f"     Snippets: {claim.snippet_ids}")
        print(f"     Quotes: {claim.verbatim_quotes}")
