#!/usr/bin/env python3
"""
Metric Canonicalization Audit (CEO-DIR-2026-101)
================================================
Phase A1: Inventory all metric sources and determine canonical status.

This script audits all metric tables in the FjordHQ database and produces
an inventory of metric sources with gap analysis.

Constitutional Alignment: ADR-018, ADR-019, ADR-020, ADR-021
Generated By: STIG (EC-003_2026_PRODUCTION)
"""

import os
import json
import hashlib
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional
import psycopg2
from psycopg2.extras import RealDictCursor

# Database connection parameters
DB_CONFIG = {
    'host': os.getenv('PGHOST', '127.0.0.1'),
    'port': int(os.getenv('PGPORT', 54322)),
    'database': os.getenv('PGDATABASE', 'postgres'),
    'user': os.getenv('PGUSER', 'postgres'),
    'password': os.getenv('PGPASSWORD', 'postgres')
}

# Metric definitions per CEO-DIR-2026-101
METRIC_DEFINITIONS = {
    'brier_score': {
        'definition': 'Squared error between forecast probability and actual outcome: (forecast - outcome)^2',
        'measurement_level': 'RATIO',
        'units_and_range': {'unit': 'squared_probability', 'min': 0.0, 'max': 1.0},
        'eligibility_criteria': 'Forecast must have paired outcome, ex-ante verified',
        'aggregation_rule': 'Mean across forecasts, weighted by regime if specified',
        'canonical_source': 'fhq_governance.brier_score_ledger'
    },
    'hit_rate_crypto': {
        'definition': 'Ratio of correct directional predictions to total predictions (crypto scope)',
        'measurement_level': 'RATIO',
        'units_and_range': {'unit': 'proportion', 'min': 0.0, 'max': 1.0},
        'eligibility_criteria': 'Crypto assets only, T+1 horizon',
        'aggregation_rule': 'Sum(correct) / Sum(total) - NO cross-scope averaging',
        'canonical_source': 'fhq_research.crypto_regime_quality_metrics.hit_rate_1d'
    },
    'hit_rate_ldow': {
        'definition': 'Ratio of correct predictions to total in LDOW cycle (cross-asset scope)',
        'measurement_level': 'RATIO',
        'units_and_range': {'unit': 'proportion', 'min': 0.0, 'max': 1.0},
        'eligibility_criteria': 'LDOW cycle forecasts only',
        'aggregation_rule': 'Sum(correct) / Sum(total) per cycle - NO cross-scope averaging',
        'canonical_source': 'fhq_governance.ldow_cycle_completion.hit_rate'
    },
    'gfi': {
        'definition': 'Geopolitical Friction Index: 0.30*Tariff + 0.35*Bilateral + 0.20*Sanctions + 0.15*Diplomatic',
        'measurement_level': 'RATIO',
        'units_and_range': {'unit': 'index', 'min': 0.0, 'max': 1.0},
        'eligibility_criteria': 'Daily observation required',
        'aggregation_rule': 'Not aggregated - daily point value',
        'canonical_source': 'fhq_macro.geopolitical_friction_data'
    },
    'fss': {
        'definition': 'Forecast Skill Score: 1 - (Brier / Brier_ref)',
        'measurement_level': 'RATIO',
        'units_and_range': {'unit': 'skill_ratio', 'min': float('-inf'), 'max': 1.0},
        'eligibility_criteria': 'Requires Brier and Brier_ref to be defined',
        'aggregation_rule': 'Compute from aggregated Brier values',
        'canonical_source': 'fhq_research.forecast_skill_metrics.brier_skill_score'
    },
    'lvi': {
        'definition': 'Learning Velocity Index: rate of forecast skill improvement over time',
        'measurement_level': 'RATIO',
        'units_and_range': {'unit': 'learning_rate', 'min': 0.0, 'max': 1.0},
        'eligibility_criteria': 'Requires at least 7 days of Brier history',
        'aggregation_rule': 'Regime-weighted decay: Σ(Event × Regime_Weight × Decay)',
        'canonical_source': 'fhq_governance.lvi_canonical'
    },
    'autonomy_clock': {
        'definition': 'Consecutive days of autonomous operation without manual intervention',
        'measurement_level': 'ORDINAL',
        'units_and_range': {'unit': 'days', 'min': 0, 'max': None},
        'eligibility_criteria': 'Reset on any manual override',
        'aggregation_rule': 'Not aggregated - single counter',
        'canonical_source': 'fhq_governance.autonomy_clock_state'
    },
    'golden_needle_eqs': {
        'definition': 'Expected Quality Score for Golden Needle signals',
        'measurement_level': 'RATIO',
        'units_and_range': {'unit': 'score', 'min': 0.0, 'max': 1.0},
        'eligibility_criteria': 'VEGA-attested Golden Needle only',
        'aggregation_rule': 'Individual per needle, no system aggregation',
        'canonical_source': 'fhq_research.golden_needle_signals'
    }
}


class MetricCanonicalizer:
    """Audits and canonicalizes metric sources."""

    def __init__(self):
        self.conn = None
        self.audit_results = {}
        self.gaps = []

    def connect(self):
        """Establish database connection."""
        self.conn = psycopg2.connect(**DB_CONFIG)

    def close(self):
        """Close database connection."""
        if self.conn:
            self.conn.close()

    def compute_hash(self, data: Any) -> str:
        """Compute SHA-256 hash of data."""
        serialized = json.dumps(data, sort_keys=True, default=str)
        return f"sha256:{hashlib.sha256(serialized.encode()).hexdigest()}"

    def execute_query(self, query: str, params: tuple = None) -> List[Dict]:
        """Execute query and return results."""
        with self.conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(query, params)
            return [dict(row) for row in cur.fetchall()]

    def audit_brier_score(self) -> Dict:
        """Audit Brier Score Ledger."""
        query = """
        SELECT
            COUNT(*) as total_rows,
            COUNT(squared_error) as non_null_values,
            AVG(squared_error) as avg_brier,
            MIN(forecast_timestamp) as earliest_date,
            MAX(forecast_timestamp) as latest_date,
            COUNT(DISTINCT asset_id) as unique_assets,
            COUNT(DISTINCT regime) as unique_regimes
        FROM fhq_governance.brier_score_ledger
        """
        result = self.execute_query(query)[0]

        # Check temporal integrity
        integrity_query = """
        SELECT
            COUNT(*) as total,
            SUM(CASE WHEN forecast_timestamp < outcome_timestamp THEN 1 ELSE 0 END) as ex_ante_valid,
            SUM(CASE WHEN forecast_timestamp >= outcome_timestamp THEN 1 ELSE 0 END) as ex_post_contaminated
        FROM fhq_governance.brier_score_ledger
        WHERE outcome_timestamp IS NOT NULL
        """
        integrity = self.execute_query(integrity_query)[0]

        return {
            'metric_name': 'Brier Score',
            'canonical_source': 'fhq_governance.brier_score_ledger',
            'status': 'OPERATIONAL',
            'total_rows': int(result['total_rows']),
            'non_null_values': int(result['non_null_values']),
            'avg_value': float(result['avg_brier']) if result['avg_brier'] else None,
            'date_range': {
                'earliest': str(result['earliest_date']) if result['earliest_date'] else None,
                'latest': str(result['latest_date']) if result['latest_date'] else None
            },
            'unique_assets': int(result['unique_assets']),
            'unique_regimes': int(result['unique_regimes']),
            'temporal_integrity': {
                'total_with_outcomes': int(integrity['total']),
                'ex_ante_valid': int(integrity['ex_ante_valid']),
                'ex_post_contaminated': int(integrity['ex_post_contaminated'])
            },
            'compliance': 'COMPLIANT',
            'definition_verified': True
        }

    def audit_fss(self) -> Dict:
        """Audit Forecast Skill Score (FSS)."""
        # Check if table exists
        table_query = """
        SELECT COUNT(*) as cnt FROM information_schema.tables
        WHERE table_schema = 'fhq_research' AND table_name = 'forecast_skill_metrics'
        """
        table_exists = self.execute_query(table_query)[0]['cnt'] > 0

        if not table_exists:
            return {
                'metric_name': 'FSS (Forecast Skill Score)',
                'canonical_source': 'fhq_research.forecast_skill_metrics.brier_skill_score',
                'status': 'TABLE_MISSING',
                'compliance': 'NON-COMPLIANT',
                'gap_id': 'GAP-COMP-001',
                'remediation': 'Create compute_fss() function and populate'
            }

        # Check FSS column population
        query = """
        SELECT
            COUNT(*) as total_rows,
            COUNT(brier_skill_score) as non_null_fss,
            SUM(CASE WHEN brier_skill_score IS NULL THEN 1 ELSE 0 END) as null_fss
        FROM fhq_research.forecast_skill_metrics
        """
        result = self.execute_query(query)[0]

        # Check if compute_fss function exists
        func_query = """
        SELECT COUNT(*) as cnt FROM information_schema.routines
        WHERE routine_schema = 'fhq_research' AND routine_name = 'compute_fss'
        """
        func_exists = self.execute_query(func_query)[0]['cnt'] > 0

        status = 'OPERATIONAL' if result['non_null_fss'] > 0 else 'BLOCKED'
        compliance = 'COMPLIANT' if result['non_null_fss'] > 0 and func_exists else 'NON-COMPLIANT'

        return {
            'metric_name': 'FSS (Forecast Skill Score)',
            'canonical_source': 'fhq_research.forecast_skill_metrics.brier_skill_score',
            'status': status,
            'total_rows': int(result['total_rows']),
            'non_null_values': int(result['non_null_fss']),
            'null_values': int(result['null_fss']),
            'compute_function_exists': func_exists,
            'compliance': compliance,
            'gap_id': 'GAP-COMP-001' if compliance == 'NON-COMPLIANT' else None,
            'remediation': 'Implement compute_fss() function (Migration 270)' if compliance == 'NON-COMPLIANT' else None
        }

    def audit_lvi(self) -> Dict:
        """Audit Learning Velocity Index (LVI)."""
        # Check if lvi_canonical table exists
        table_query = """
        SELECT COUNT(*) as cnt FROM information_schema.tables
        WHERE table_schema = 'fhq_governance' AND table_name = 'lvi_canonical'
        """
        table_exists = self.execute_query(table_query)[0]['cnt'] > 0

        if not table_exists:
            return {
                'metric_name': 'LVI (Learning Velocity Index)',
                'canonical_source': 'fhq_governance.lvi_canonical',
                'status': 'TABLE_MISSING',
                'compliance': 'NON-COMPLIANT',
                'gap_id': 'GAP-COMP-002',
                'remediation': 'Create lvi_canonical table (Migration 271)'
            }

        query = """
        SELECT
            COUNT(*) as total_rows,
            AVG(lvi_value) as avg_lvi,
            MIN(computed_at) as earliest,
            MAX(computed_at) as latest
        FROM fhq_governance.lvi_canonical
        """
        result = self.execute_query(query)[0]

        return {
            'metric_name': 'LVI (Learning Velocity Index)',
            'canonical_source': 'fhq_governance.lvi_canonical',
            'status': 'OPERATIONAL' if result['total_rows'] > 0 else 'EMPTY',
            'total_rows': int(result['total_rows']),
            'avg_value': float(result['avg_lvi']) if result['avg_lvi'] else None,
            'compliance': 'COMPLIANT' if result['total_rows'] > 0 else 'NON-COMPLIANT'
        }

    def audit_autonomy_clock(self) -> Dict:
        """Audit Autonomy Clock State."""
        table_query = """
        SELECT COUNT(*) as cnt FROM information_schema.tables
        WHERE table_schema = 'fhq_governance' AND table_name = 'autonomy_clock_state'
        """
        table_exists = self.execute_query(table_query)[0]['cnt'] > 0

        if not table_exists:
            return {
                'metric_name': 'Autonomy Clock',
                'canonical_source': 'fhq_governance.autonomy_clock_state',
                'status': 'TABLE_MISSING',
                'compliance': 'NON-COMPLIANT',
                'gap_id': 'GAP-STATE-002',
                'remediation': 'Create autonomy_clock_state table (Migration 272)'
            }

        query = """
        SELECT consecutive_days, state, updated_at
        FROM fhq_governance.autonomy_clock_state
        ORDER BY updated_at DESC LIMIT 1
        """
        result = self.execute_query(query)

        return {
            'metric_name': 'Autonomy Clock',
            'canonical_source': 'fhq_governance.autonomy_clock_state',
            'status': 'OPERATIONAL' if result else 'EMPTY',
            'current_value': result[0] if result else None,
            'compliance': 'COMPLIANT' if result else 'NON-COMPLIANT'
        }

    def audit_regime_states(self) -> Dict:
        """Audit Regime States for BIFURCATED_LIQUIDITY."""
        query = """
        SELECT
            COUNT(*) as total_rows,
            COUNT(DISTINCT regime_state) as unique_regimes,
            array_agg(DISTINCT regime_state::text) as regime_values
        FROM fhq_research.regime_states
        """
        result = self.execute_query(query)[0]

        # Check for BIFURCATED_LIQUIDITY in regime values
        regimes = result['regime_values'] if result['regime_values'] else []
        has_bifurcated = any('BIFURCATED' in str(r).upper() for r in regimes)

        # Check provisional schema
        schema_query = """
        SELECT COUNT(*) as cnt FROM information_schema.schemata
        WHERE schema_name = 'fhq_provisional'
        """
        provisional_exists = self.execute_query(schema_query)[0]['cnt'] > 0

        return {
            'metric_name': 'Regime States',
            'canonical_source': 'fhq_research.regime_states',
            'status': 'OPERATIONAL',
            'total_rows': int(result['total_rows']),
            'unique_regimes': int(result['unique_regimes']),
            'regime_values': regimes,
            'bifurcated_liquidity': {
                'registered': has_bifurcated,
                'provisional_schema_exists': provisional_exists,
                'gap_id': 'GAP-STATE-001' if not has_bifurcated else None,
                'remediation': 'Register BIFURCATED_LIQUIDITY in regime_model_registry (G4 required)' if not has_bifurcated else None
            },
            'compliance': 'COMPLIANT' if has_bifurcated else 'PARTIAL'
        }

    def audit_gfi(self) -> Dict:
        """Audit Geopolitical Friction Index (GFI)."""
        query = """
        SELECT
            COUNT(*) as total_rows,
            AVG(gfi_index) as avg_gfi,
            MIN(observation_date) as earliest,
            MAX(observation_date) as latest
        FROM fhq_macro.geopolitical_friction_data
        """
        result = self.execute_query(query)[0]

        return {
            'metric_name': 'GFI (Geopolitical Friction Index)',
            'canonical_source': 'fhq_macro.geopolitical_friction_data',
            'status': 'OPERATIONAL',
            'total_rows': int(result['total_rows']),
            'avg_value': float(result['avg_gfi']) if result['avg_gfi'] else None,
            'date_range': {
                'earliest': str(result['earliest']) if result['earliest'] else None,
                'latest': str(result['latest']) if result['latest'] else None
            },
            'compliance': 'COMPLIANT'
        }

    def audit_hit_rates(self) -> Dict:
        """Audit Hit Rate metrics (two canonical scopes)."""
        # Crypto scope
        crypto_query = """
        SELECT
            COUNT(*) as total_rows,
            COUNT(hit_rate_1d) as non_null_hit_rate,
            AVG(hit_rate_1d) as avg_hit_rate
        FROM fhq_research.crypto_regime_quality_metrics
        """
        crypto_result = self.execute_query(crypto_query)[0]

        # LDOW scope
        ldow_query = """
        SELECT
            COUNT(*) as total_cycles,
            AVG(hit_rate) as avg_hit_rate,
            MIN(completed_at) as earliest,
            MAX(completed_at) as latest
        FROM fhq_governance.ldow_cycle_completion
        """
        ldow_result = self.execute_query(ldow_query)[0]

        return {
            'metric_name': 'Hit Rate',
            'canonical_scopes': {
                'crypto': {
                    'source': 'fhq_research.crypto_regime_quality_metrics.hit_rate_1d',
                    'total_rows': int(crypto_result['total_rows']),
                    'non_null_values': int(crypto_result['non_null_hit_rate']),
                    'avg_value': float(crypto_result['avg_hit_rate']) if crypto_result['avg_hit_rate'] else None,
                    'status': 'OPERATIONAL' if crypto_result['non_null_hit_rate'] > 0 else 'EMPTY'
                },
                'ldow': {
                    'source': 'fhq_governance.ldow_cycle_completion.hit_rate',
                    'total_cycles': int(ldow_result['total_cycles']),
                    'avg_value': float(ldow_result['avg_hit_rate']) if ldow_result['avg_hit_rate'] else None,
                    'date_range': {
                        'earliest': str(ldow_result['earliest']) if ldow_result['earliest'] else None,
                        'latest': str(ldow_result['latest']) if ldow_result['latest'] else None
                    },
                    'status': 'OPERATIONAL' if ldow_result['total_cycles'] > 0 else 'EMPTY'
                }
            },
            'canonical_rule': 'TWO_SCOPES_SEPARATE_CANON - NO cross-aggregation permitted',
            'compliance': 'COMPLIANT'
        }

    def audit_calibration_bins(self) -> Dict:
        """Audit Calibration Bins table (ADR-019)."""
        table_query = """
        SELECT COUNT(*) as cnt FROM information_schema.tables
        WHERE table_schema = 'fhq_governance' AND table_name = 'calibration_bins'
        """
        table_exists = self.execute_query(table_query)[0]['cnt'] > 0

        if not table_exists:
            return {
                'metric_name': 'Calibration Bins',
                'canonical_source': 'fhq_governance.calibration_bins',
                'status': 'TABLE_MISSING',
                'compliance': 'NON-COMPLIANT',
                'gap_id': 'GAP-COMP-003',
                'remediation': 'Create calibration_bins table (Migration 273)',
                'adr_reference': 'ADR-019'
            }

        query = """
        SELECT COUNT(*) as total_bins
        FROM fhq_governance.calibration_bins
        """
        result = self.execute_query(query)[0]

        return {
            'metric_name': 'Calibration Bins',
            'canonical_source': 'fhq_governance.calibration_bins',
            'status': 'OPERATIONAL' if result['total_bins'] > 0 else 'EMPTY',
            'total_bins': int(result['total_bins']),
            'compliance': 'COMPLIANT' if result['total_bins'] >= 10 else 'PARTIAL',
            'adr_reference': 'ADR-019'
        }

    def audit_confidence_ceiling(self) -> Dict:
        """Audit 0.60 Confidence Ceiling in calibration gates."""
        query = """
        SELECT
            gate_id,
            forecast_type,
            regime,
            confidence_ceiling,
            effective_from,
            effective_until,
            approved_by
        FROM fhq_governance.confidence_calibration_gates
        WHERE confidence_ceiling IS NOT NULL
        ORDER BY effective_from DESC
        """
        results = self.execute_query(query)

        has_060_ceiling = any(
            r['confidence_ceiling'] == 0.60 for r in results
        )

        return {
            'metric_name': '0.60 Confidence Ceiling',
            'canonical_source': 'fhq_governance.confidence_calibration_gates',
            'status': 'OPERATIONAL' if has_060_ceiling else 'NOT_VERSIONED',
            'total_gates': len(results),
            'ceilings_found': [
                {
                    'ceiling': float(r['confidence_ceiling']),
                    'forecast_type': r['forecast_type'],
                    'regime': r['regime']
                }
                for r in results[:5]  # First 5
            ],
            'compliance': 'COMPLIANT' if has_060_ceiling else 'NON-COMPLIANT',
            'gap_id': 'GAP-REG-001' if not has_060_ceiling else None,
            'remediation': 'Insert 0.60 ceiling into confidence_calibration_gates' if not has_060_ceiling else None
        }

    def run_full_audit(self) -> Dict:
        """Run complete metric canonicalization audit."""
        self.connect()

        try:
            audit_timestamp = datetime.now(timezone.utc).isoformat()

            # Run all audits
            metrics = {
                'brier_score': self.audit_brier_score(),
                'fss': self.audit_fss(),
                'lvi': self.audit_lvi(),
                'autonomy_clock': self.audit_autonomy_clock(),
                'regime_states': self.audit_regime_states(),
                'gfi': self.audit_gfi(),
                'hit_rates': self.audit_hit_rates(),
                'calibration_bins': self.audit_calibration_bins(),
                'confidence_ceiling': self.audit_confidence_ceiling()
            }

            # Collect gaps
            gaps = []
            for name, result in metrics.items():
                if result.get('gap_id'):
                    gaps.append({
                        'gap_id': result['gap_id'],
                        'entity': name,
                        'current_state': result['status'],
                        'remediation': result.get('remediation'),
                        'priority': self._determine_priority(result['gap_id'])
                    })
                # Check nested gaps (e.g., bifurcated_liquidity)
                if 'bifurcated_liquidity' in result:
                    bf = result['bifurcated_liquidity']
                    if bf.get('gap_id'):
                        gaps.append({
                            'gap_id': bf['gap_id'],
                            'entity': 'BIFURCATED_LIQUIDITY',
                            'current_state': 'NOT_REGISTERED',
                            'remediation': bf.get('remediation'),
                            'priority': 'P1'
                        })

            # Compute compliance summary
            compliant_count = sum(1 for m in metrics.values() if m.get('compliance') == 'COMPLIANT')
            total_count = len(metrics)

            inventory = {
                'directive': 'CEO-DIR-2026-101',
                'title': 'System-Level Epistemic Verification Framework',
                'phase': 'A1',
                'purpose': 'Metric Canonicalization Inventory',
                'generated_at': audit_timestamp,
                'generated_by': 'STIG',
                'agent_id': 'EC-003_2026_PRODUCTION',
                'metric_definitions': METRIC_DEFINITIONS,
                'audit_results': metrics,
                'gap_inventory': gaps,
                'compliance_summary': {
                    'compliant_metrics': compliant_count,
                    'total_metrics': total_count,
                    'compliance_rate': round(compliant_count / total_count, 4),
                    'blocked_entities': len(gaps)
                },
                'verification_status': 'PENDING_VEGA_ATTESTATION',
                'state_snapshot_hash': self.compute_hash(metrics)
            }

            return inventory

        finally:
            self.close()

    def _determine_priority(self, gap_id: str) -> str:
        """Determine priority based on gap ID."""
        priority_map = {
            'GAP-COMP-001': 'P0',  # FSS - critical for SkillDamper
            'GAP-COMP-002': 'P1',  # LVI
            'GAP-COMP-003': 'P2',  # Calibration bins
            'GAP-STATE-001': 'P1', # BIFURCATED regime
            'GAP-STATE-002': 'P1', # Autonomy clock
            'GAP-REG-001': 'P2'    # 0.60 ceiling
        }
        return priority_map.get(gap_id, 'P2')


def main():
    """Run the metric canonicalization audit and save results."""
    print("=" * 60)
    print("METRIC CANONICALIZATION AUDIT (CEO-DIR-2026-101)")
    print("Phase A1: Inventory - NO MODIFICATIONS")
    print("=" * 60)

    auditor = MetricCanonicalizer()
    inventory = auditor.run_full_audit()

    # Save to evidence file
    evidence_path = os.path.join(
        os.path.dirname(__file__),
        'evidence',
        'CEO_DIR_2026_101_METRIC_CANONICALIZATION_INVENTORY.json'
    )

    os.makedirs(os.path.dirname(evidence_path), exist_ok=True)

    with open(evidence_path, 'w') as f:
        json.dump(inventory, f, indent=2, default=str)

    print(f"\nInventory saved to: {evidence_path}")
    print(f"\nCompliance Summary:")
    print(f"  Compliant: {inventory['compliance_summary']['compliant_metrics']}/{inventory['compliance_summary']['total_metrics']}")
    print(f"  Rate: {inventory['compliance_summary']['compliance_rate']*100:.1f}%")
    print(f"  Gaps Found: {inventory['compliance_summary']['blocked_entities']}")

    print("\nGap Inventory:")
    for gap in inventory['gap_inventory']:
        print(f"  [{gap['priority']}] {gap['gap_id']}: {gap['entity']} - {gap['current_state']}")

    print("\n" + "=" * 60)
    print("AUDIT COMPLETE - PENDING VEGA ATTESTATION")
    print("=" * 60)

    return inventory


if __name__ == '__main__':
    main()
