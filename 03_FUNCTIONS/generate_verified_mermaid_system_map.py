"""
Verified Mermaid System Map Generator
CEO-DIR-2026-VISUAL-TRUTH-001

Generates a DB-sourced, verifiable Mermaid diagram of the FjordHQ Cognitive Engine.
Every node and edge is traceable to database introspection.

NON-NEGOTIABLE: No manual diagrams. No "looks right". DB-sourced truth only.

Author: STIG (CTO)
Date: 2026-01-04
Constitutional: ADR-017, ADR-020, ADR-021
"""

import os
import sys
import json
import hashlib
import psycopg2
from datetime import datetime, timezone
from typing import Dict, List, Any, Tuple
import requests

# Load environment
from dotenv import load_dotenv
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env'), override=True)


# =============================================================================
# NORDIC FJORDHQ THEME
# =============================================================================
NORDIC_THEME = '''%%{init: {
  "theme": "base",
  "themeVariables": {
    "background": "#0d1117",
    "primaryColor": "#1e3a5f",
    "primaryTextColor": "#c9d1d9",
    "primaryBorderColor": "#30363d",
    "secondaryColor": "#21262d",
    "secondaryTextColor": "#8b949e",
    "tertiaryColor": "#161b22",
    "lineColor": "#58a6ff",
    "textColor": "#c9d1d9",
    "mainBkg": "#161b22",
    "nodeBorder": "#30363d",
    "clusterBkg": "#0d1117",
    "clusterBorder": "#21262d",
    "titleColor": "#58a6ff",
    "edgeLabelBackground": "#161b22",
    "nodeTextColor": "#c9d1d9"
  }
}}%%'''


def get_db_connection():
    return psycopg2.connect(
        host=os.getenv('PGHOST', '127.0.0.1'),
        port=int(os.getenv('PGPORT', '54322')),
        database=os.getenv('PGDATABASE', 'postgres'),
        user=os.getenv('PGUSER', 'postgres'),
        password=os.getenv('PGPASSWORD', 'postgres')
    )


def get_qdrant_status() -> Dict[str, Any]:
    """Get Qdrant collection stats via REST API."""
    try:
        resp = requests.get('http://localhost:6333/collections', timeout=5)
        if resp.status_code == 200:
            collections = resp.json().get('result', {}).get('collections', [])
            result = {}
            for coll in collections:
                name = coll['name']
                detail_resp = requests.get(f'http://localhost:6333/collections/{name}', timeout=5)
                if detail_resp.status_code == 200:
                    detail = detail_resp.json().get('result', {})
                    result[name] = {
                        'points_count': detail.get('points_count', 0),
                        'status': detail.get('status', 'unknown')
                    }
            return result
    except Exception as e:
        return {'error': str(e)}
    return {}


def get_table_stats(conn) -> Dict[str, Dict]:
    """Get row counts and column counts for target tables."""
    cursor = conn.cursor()

    # Target tables for the cognitive engine
    target_tables = [
        'fhq_memory.conversations',
        'fhq_memory.conversation_messages',
        'fhq_memory.embedding_store',
        'fhq_memory.archival_store',
        'fhq_canonical.evidence_nodes',
        'fhq_canonical.evidence_bundles',
        'fhq_canonical.evidence_relationships',
        'fhq_governance.inforage_query_log',
        'fhq_graph.nodes',
        'fhq_graph.edges'
    ]

    stats = {}
    for table in target_tables:
        schema, name = table.split('.')
        try:
            cursor.execute(f"SELECT COUNT(*) FROM {table}")
            row_count = cursor.fetchone()[0]

            cursor.execute("""
                SELECT COUNT(*) FROM information_schema.columns
                WHERE table_schema = %s AND table_name = %s
            """, [schema, name])
            col_count = cursor.fetchone()[0]

            stats[table] = {
                'row_count': row_count,
                'col_count': col_count,
                'exists': True
            }
        except Exception as e:
            stats[table] = {
                'row_count': 0,
                'col_count': 0,
                'exists': False,
                'error': str(e)
            }

    cursor.close()
    return stats


def get_fk_relationships(conn) -> List[Dict]:
    """Get foreign key relationships from DB metadata."""
    cursor = conn.cursor()

    cursor.execute("""
        SELECT
            tc.table_schema || '.' || tc.table_name as from_table,
            kcu.column_name as from_column,
            ccu.table_schema || '.' || ccu.table_name as to_table,
            ccu.column_name as to_column
        FROM information_schema.table_constraints tc
        JOIN information_schema.key_column_usage kcu
            ON tc.constraint_name = kcu.constraint_name
            AND tc.table_schema = kcu.table_schema
        JOIN information_schema.constraint_column_usage ccu
            ON ccu.constraint_name = tc.constraint_name
            AND ccu.table_schema = tc.table_schema
        WHERE tc.constraint_type = 'FOREIGN KEY'
          AND (
              tc.table_schema IN ('fhq_memory', 'fhq_canonical', 'fhq_governance', 'fhq_graph')
              OR ccu.table_schema IN ('fhq_memory', 'fhq_canonical', 'fhq_governance', 'fhq_graph')
          )
          AND tc.table_name IN (
              'conversations', 'conversation_messages', 'embedding_store',
              'archival_store', 'evidence_nodes', 'evidence_bundles',
              'evidence_relationships', 'inforage_query_log', 'nodes', 'edges'
          )
        ORDER BY tc.table_schema, tc.table_name
    """)

    relationships = []
    for row in cursor.fetchall():
        relationships.append({
            'from_table': row[0],
            'from_column': row[1],
            'to_table': row[2],
            'to_column': row[3],
            'verified': True
        })

    cursor.close()
    return relationships


def get_qdrant_sync_stats(conn) -> Dict[str, int]:
    """Get Qdrant sync statistics from evidence_nodes."""
    cursor = conn.cursor()

    cursor.execute("""
        SELECT
            COUNT(*) as total,
            COUNT(*) FILTER (WHERE qdrant_point_id IS NOT NULL) as synced,
            COUNT(DISTINCT qdrant_collection) as collections
        FROM fhq_canonical.evidence_nodes
    """)

    row = cursor.fetchone()
    cursor.close()

    return {
        'total_evidence': row[0],
        'synced_to_qdrant': row[1],
        'collections_used': row[2]
    }


def generate_mermaid(
    table_stats: Dict,
    relationships: List[Dict],
    qdrant_stats: Dict,
    qdrant_sync: Dict
) -> str:
    """Generate Mermaid flowchart from DB metadata."""

    lines = [NORDIC_THEME, '', 'flowchart TD']

    # ==========================================================================
    # SUBGRAPH: PIPELINE PHASES
    # ==========================================================================
    lines.append('')
    lines.append('    subgraph PIPELINE["ðŸ”· COGNITIVE ENGINE PIPELINE"]')
    lines.append('        direction LR')
    lines.append('        P0["P0: Data Liveness"]')
    lines.append('        P1["P1: Embedding Gen"]')
    lines.append('        P2["P2: Hybrid Retrieval"]')
    lines.append('        P3["P3: IKEA Grounding"]')
    lines.append('        P4["P4: Memory Stack"]')
    lines.append('        P5["P5: Evidence Bundle"]')
    lines.append('        P0 --> P1 --> P2 --> P3 --> P4 --> P5')
    lines.append('    end')

    # ==========================================================================
    # SUBGRAPH: MEMORY
    # ==========================================================================
    lines.append('')
    lines.append('    subgraph MEMORY["ðŸ’¾ fhq_memory"]')
    lines.append('        direction TB')

    mem_tables = [k for k in table_stats if k.startswith('fhq_memory')]
    for table in mem_tables:
        stats = table_stats[table]
        short_name = table.split('.')[1]
        node_id = short_name.upper()
        if stats['exists']:
            label = f"{short_name}\\n({stats['row_count']} rows)"
        else:
            label = f"{short_name}\\n[NOT FOUND]"
        lines.append(f'        {node_id}["{label}"]')

    lines.append('    end')

    # ==========================================================================
    # SUBGRAPH: CANONICAL (Evidence)
    # ==========================================================================
    lines.append('')
    lines.append('    subgraph CANONICAL["ðŸ“œ fhq_canonical"]')
    lines.append('        direction TB')

    can_tables = [k for k in table_stats if k.startswith('fhq_canonical')]
    for table in can_tables:
        stats = table_stats[table]
        short_name = table.split('.')[1]
        node_id = short_name.upper()
        if stats['exists']:
            label = f"{short_name}\\n({stats['row_count']} rows)"
        else:
            label = f"{short_name}\\n[NOT FOUND]"
        lines.append(f'        {node_id}["{label}"]')

    lines.append('    end')

    # ==========================================================================
    # SUBGRAPH: GOVERNANCE
    # ==========================================================================
    lines.append('')
    lines.append('    subgraph GOVERNANCE["âš–ï¸ fhq_governance"]')
    lines.append('        direction TB')

    gov_tables = [k for k in table_stats if k.startswith('fhq_governance')]
    for table in gov_tables:
        stats = table_stats[table]
        short_name = table.split('.')[1]
        node_id = short_name.upper()
        if stats['exists']:
            label = f"{short_name}\\n({stats['row_count']} rows)"
        else:
            label = f"{short_name}\\n[NOT FOUND]"
        lines.append(f'        {node_id}["{label}"]')

    lines.append('    end')

    # ==========================================================================
    # SUBGRAPH: GRAPH
    # ==========================================================================
    lines.append('')
    lines.append('    subgraph GRAPH["ðŸ•¸ï¸ fhq_graph"]')
    lines.append('        direction TB')

    graph_tables = [k for k in table_stats if k.startswith('fhq_graph')]
    for table in graph_tables:
        stats = table_stats[table]
        short_name = table.split('.')[1]
        node_id = 'GRAPH_' + short_name.upper()
        if stats['exists']:
            label = f"{short_name}\\n({stats['row_count']} rows)"
        else:
            label = f"{short_name}\\n[NOT FOUND]"
        lines.append(f'        {node_id}["{label}"]')

    lines.append('    end')

    # ==========================================================================
    # SUBGRAPH: QDRANT
    # ==========================================================================
    lines.append('')
    lines.append('    subgraph QDRANT["ðŸ” Qdrant Vector Store"]')
    lines.append('        direction TB')

    if isinstance(qdrant_stats, dict) and 'error' not in qdrant_stats:
        for coll_name, coll_stats in qdrant_stats.items():
            node_id = 'QDRANT_' + coll_name.upper().replace('-', '_')
            points = coll_stats.get('points_count', 0)
            status = coll_stats.get('status', 'unknown')
            label = f"{coll_name}\\n({points} vectors)\\nstatus: {status}"
            lines.append(f'        {node_id}["{label}"]')
    else:
        lines.append('        QDRANT_ERROR["Qdrant unavailable"]')

    lines.append('    end')

    # ==========================================================================
    # EDGES: FK Relationships (VERIFIED)
    # ==========================================================================
    lines.append('')
    lines.append('    %% FK Relationships (DB-Verified)')

    added_edges = set()
    for rel in relationships:
        from_short = rel['from_table'].split('.')[1].upper()
        to_short = rel['to_table'].split('.')[1].upper()

        # Handle graph schema prefix
        if 'fhq_graph' in rel['from_table']:
            from_short = 'GRAPH_' + from_short
        if 'fhq_graph' in rel['to_table']:
            to_short = 'GRAPH_' + to_short

        edge_key = f"{from_short}-->{to_short}"
        if edge_key not in added_edges:
            label = f"{rel['from_column']}"
            lines.append(f'    {from_short} -->|{label}| {to_short}')
            added_edges.add(edge_key)

    # ==========================================================================
    # EDGES: Qdrant Sync (Logical - based on qdrant_point_id column)
    # ==========================================================================
    lines.append('')
    lines.append('    %% Qdrant Sync Linkage')
    if qdrant_sync['synced_to_qdrant'] > 0:
        lines.append(f'    EVIDENCE_NODES -.->|{qdrant_sync["synced_to_qdrant"]} synced| QDRANT_EVIDENCE_NODES')

    # ==========================================================================
    # EDGES: Pipeline to Tables (Logical)
    # ==========================================================================
    lines.append('')
    lines.append('    %% Pipeline Phase Connections')
    lines.append('    P1 -.-> EMBEDDING_STORE')
    lines.append('    P2 -.-> EVIDENCE_NODES')
    lines.append('    P2 -.-> QDRANT_EVIDENCE_NODES')
    lines.append('    P3 -.-> EVIDENCE_BUNDLES')
    lines.append('    P4 -.-> ARCHIVAL_STORE')
    lines.append('    P5 -.-> INFORAGE_QUERY_LOG')

    # ==========================================================================
    # STYLING
    # ==========================================================================
    lines.append('')
    lines.append('    %% Styling')
    lines.append('    classDef memory fill:#1a365d,stroke:#2c5282,color:#bee3f8')
    lines.append('    classDef canonical fill:#234e52,stroke:#319795,color:#b2f5ea')
    lines.append('    classDef governance fill:#553c9a,stroke:#805ad5,color:#e9d8fd')
    lines.append('    classDef graph fill:#744210,stroke:#d69e2e,color:#fefcbf')
    lines.append('    classDef qdrant fill:#702459,stroke:#b83280,color:#fed7e2')
    lines.append('    classDef pipeline fill:#1e3a5f,stroke:#58a6ff,color:#c9d1d9')
    lines.append('')
    lines.append('    class CONVERSATIONS,CONVERSATION_MESSAGES,EMBEDDING_STORE,ARCHIVAL_STORE memory')
    lines.append('    class EVIDENCE_NODES,EVIDENCE_BUNDLES,EVIDENCE_RELATIONSHIPS canonical')
    lines.append('    class INFORAGE_QUERY_LOG governance')
    lines.append('    class GRAPH_NODES,GRAPH_EDGES graph')
    lines.append('    class QDRANT_EVIDENCE_NODES,QDRANT_FINN_EMBEDDINGS,QDRANT_CAUSAL_CLAIMS qdrant')
    lines.append('    class P0,P1,P2,P3,P4,P5 pipeline')

    return '\n'.join(lines)


def compute_hash(content: str) -> str:
    """Compute SHA-256 hash of content."""
    return hashlib.sha256(content.encode('utf-8')).hexdigest()


def run_generator():
    """Main generator function."""
    print("=" * 70)
    print("VERIFIED MERMAID SYSTEM MAP GENERATOR")
    print("CEO-DIR-2026-VISUAL-TRUTH-001")
    print(f"Timestamp: {datetime.now(timezone.utc).isoformat()}")
    print("=" * 70)

    conn = get_db_connection()

    # Collect all SQL queries for verification
    sql_queries = []

    # Step 1: Get table statistics
    print("\n[1/4] Querying table statistics...")
    table_stats = get_table_stats(conn)
    sql_queries.append({
        'description': 'Table row counts',
        'tables_queried': list(table_stats.keys())
    })

    for table, stats in table_stats.items():
        status = f"{stats['row_count']} rows" if stats['exists'] else "NOT FOUND"
        print(f"       {table}: {status}")

    # Step 2: Get FK relationships
    print("\n[2/4] Querying FK relationships...")
    relationships = get_fk_relationships(conn)
    sql_queries.append({
        'description': 'FK relationships from information_schema',
        'relationships_found': len(relationships)
    })
    print(f"       Found {len(relationships)} verified FK relationships")

    # Step 3: Get Qdrant status
    print("\n[3/4] Querying Qdrant status...")
    qdrant_stats = get_qdrant_status()
    if 'error' not in qdrant_stats:
        for coll, stats in qdrant_stats.items():
            print(f"       {coll}: {stats['points_count']} vectors ({stats['status']})")
    else:
        print(f"       Qdrant unavailable: {qdrant_stats.get('error')}")

    # Step 4: Get Qdrant sync stats
    print("\n[4/4] Querying Qdrant sync status...")
    qdrant_sync = get_qdrant_sync_stats(conn)
    sql_queries.append({
        'description': 'Qdrant sync status from evidence_nodes',
        'synced': qdrant_sync['synced_to_qdrant'],
        'total': qdrant_sync['total_evidence']
    })
    print(f"       {qdrant_sync['synced_to_qdrant']}/{qdrant_sync['total_evidence']} evidence nodes synced")

    conn.close()

    # Generate Mermaid
    print("\n[GENERATING] Mermaid diagram...")
    mermaid_output = generate_mermaid(table_stats, relationships, qdrant_stats, qdrant_sync)

    # Compute hashes
    mermaid_hash = compute_hash(mermaid_output)
    sql_hash = compute_hash(json.dumps(sql_queries, sort_keys=True))
    timestamp = datetime.now(timezone.utc).isoformat()

    combined_hash = compute_hash(f"{mermaid_hash}{sql_hash}{timestamp}")

    # Create evidence artifact
    evidence = {
        'directive': 'CEO-DIR-2026-VISUAL-TRUTH-001',
        'type': 'DB_SOURCED_MERMAID_MAP',
        'timestamp': timestamp,
        'environment': {
            'db_host': os.getenv('PGHOST', '127.0.0.1'),
            'db_port': os.getenv('PGPORT', '54322'),
            'db_name': os.getenv('PGDATABASE', 'postgres'),
            'qdrant_host': 'localhost:6333'
        },
        'verification': {
            'mermaid_hash': mermaid_hash,
            'sql_queries_hash': sql_hash,
            'combined_hash': combined_hash
        },
        'sql_queries': sql_queries,
        'table_stats': table_stats,
        'fk_relationships': relationships,
        'qdrant_collections': qdrant_stats,
        'qdrant_sync': qdrant_sync,
        'mermaid_output': mermaid_output
    }

    # Write Mermaid file
    mermaid_path = os.path.join(os.path.dirname(__file__), 'system_map.mmd')
    with open(mermaid_path, 'w', encoding='utf-8') as f:
        f.write(mermaid_output)
    print(f"\n[OUTPUT] Mermaid: {mermaid_path}")

    # Write evidence artifact
    evidence_filename = f'DB_MERMAID_MAP_{datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")}.json'
    evidence_path = os.path.join(os.path.dirname(__file__), 'evidence', evidence_filename)
    with open(evidence_path, 'w', encoding='utf-8') as f:
        json.dump(evidence, f, indent=2, default=str)
    print(f"[OUTPUT] Evidence: {evidence_path}")

    # Summary
    print("\n" + "=" * 70)
    print("GENERATION COMPLETE")
    print("=" * 70)
    print(f"Tables mapped:       {len(table_stats)}")
    print(f"FK relationships:    {len(relationships)}")
    print(f"Qdrant collections:  {len(qdrant_stats) if isinstance(qdrant_stats, dict) and 'error' not in qdrant_stats else 0}")
    print(f"Evidence nodes:      {qdrant_sync['total_evidence']}")
    print(f"Synced to Qdrant:    {qdrant_sync['synced_to_qdrant']}")
    print(f"\nVerification Hash:   {combined_hash[:16]}...")
    print(f"Mermaid Hash:        {mermaid_hash[:16]}...")

    return evidence


if __name__ == '__main__':
    run_generator()
